"""
ARA v2 Orchestrator Agents.

Defines specialized agents for the multi-agent pipeline:
- PlanningAgent: Routes problems to appropriate execution path
- ExecutionAgent: Delegates to v1 for tool-based solving
- VerificationAgent: Optional cross-checking for complex problems
- SynthesisAgent: Formats final answers

Design: v1 does the heavy lifting (tools). v2 adds smart routing.
"""

import os
import re
import json
from typing import Any
from dataclasses import dataclass, field

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

from dotenv import load_dotenv
load_dotenv()


# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class SubTask:
    """A sub-task generated by the planning agent."""
    id: int
    description: str
    dependencies: list[int] = field(default_factory=list)
    result: str | None = None
    confidence: float = 0.0


@dataclass
class VerificationResult:
    """Result from the verification agent."""
    is_valid: bool
    confidence: float
    issues: list[str] = field(default_factory=list)
    corrected_answer: str | None = None


@dataclass
class OrchestratorState:
    """State passed between agents in the orchestrator."""
    query: str
    subtasks: list[SubTask] = field(default_factory=list)
    results: dict[int, str] = field(default_factory=dict)
    verification: VerificationResult | None = None
    final_answer: str | None = None
    execution_path: list[str] = field(default_factory=list)
    total_confidence: float = 0.0


# ============================================================================
# LLM CONFIGURATION
# ============================================================================

def get_llm(temperature: float = 0.1) -> ChatOpenAI:
    """Get LLM instance for orchestrator agents."""
    api_key = os.getenv("OPENROUTER_API_KEY")
    model_name = os.getenv("OPENROUTER_MODEL", "openai/gpt-4o-mini")

    if api_key:
        return ChatOpenAI(
            model=model_name,
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1",
            temperature=temperature,
            max_tokens=1024,
            timeout=60,
            default_headers={
                "HTTP-Referer": "https://github.com/puranikyashaswin/ARA",
                "X-Title": "ARA v2 Orchestrator"
            }
        )

    # Secondary OpenRouter-compatible endpoint for reliability
    fallback_key = os.getenv("FALLBACK_API_KEY") or os.getenv("NVIDIA_API_KEY")
    if fallback_key:
        return ChatOpenAI(
            model="meta/llama-3.3-70b-instruct",
            openai_api_key=fallback_key,
            openai_api_base="https://integrate.api.nvidia.com/v1",
            temperature=temperature,
            timeout=120,
        )

    raise ValueError("Missing API Configuration")


# ============================================================================
# PLANNING AGENT
# ============================================================================

PLANNING_PROMPT = """You are a Problem Router for a math reasoning agent.

Your ONLY job: Decide if a problem needs SPECIAL handling or DIRECT execution.

CRITICAL: The v1 agent is EXCELLENT. It achieves 95% accuracy by handling ALL reasoning internally.
Do NOT decompose problems unless they EXPLICITLY have labeled separate parts.

ROUTING RULES:

1. "direct" (USE 99% OF THE TIME):
   - ANY problem asking ONE question, even if multi-step internally
   - Problems with calculations, comparisons, percentages, fractions
   - Word problems involving multiple people, items, or transactions
   - "How many...", "What is...", "Calculate...", "Find..."
   - Problems that BUILD on previous calculations (they're still ONE question)

2. "decompose" (EXTREMELY RARE - maybe 1% of problems):
   - ONLY when the problem has LITERALLY LABELED SEPARATE PARTS like:
     * "Part A: ... Part B: ..."
     * "Question 1: ... Question 2: ..."
     * "First, answer X. Second, answer Y."

IF IN DOUBT â†’ ALWAYS CHOOSE "direct"

Respond with ONLY this JSON:
{{
    "execution_mode": "direct",
    "reason": "Single question - v1 handles all reasoning"
}}

Problem: {query}

JSON only:"""


class PlanningAgent:
    """Analyzes problem complexity and determines execution path."""

    def __init__(self):
        self.llm = get_llm(temperature=0.0)

    def plan(self, query: str) -> tuple[str, list[SubTask]]:
        """
        Analyze the query and determine execution path.

        Returns:
            Tuple of (complexity, list of SubTasks)
            complexity is "simple" for direct mode, "complex" for decompose mode
        """
        messages = [
            SystemMessage(content="You are a planning assistant that outputs only valid JSON."),
            HumanMessage(content=PLANNING_PROMPT.format(query=query))
        ]

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()

            # Extract JSON from response
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                data = json.loads(json_match.group())
            else:
                data = json.loads(content)

            execution_mode = data.get("execution_mode", "direct")

            # Map to complexity for backwards compatibility
            if execution_mode == "direct":
                # For direct mode, return the FULL original problem as single task
                return "simple", [SubTask(id=1, description=query, dependencies=[])]
            else:
                # For decompose mode, use the subtasks from planning
                subtasks = [
                    SubTask(
                        id=st["id"],
                        description=st["description"],
                        dependencies=st.get("dependencies", [])
                    )
                    for st in data.get("subtasks", [])
                ]

                # Ensure at least one subtask
                if not subtasks:
                    return "simple", [SubTask(id=1, description=query, dependencies=[])]

                return "complex", subtasks

        except (json.JSONDecodeError, KeyError, Exception) as e:
            # Fallback: treat as direct single-task problem (this is the SAFE default)
            return "simple", [SubTask(id=1, description=query, dependencies=[])]


# ============================================================================
# EXECUTION AGENT
# ============================================================================

class ExecutionAgent:
    """Executes tasks using the v1 agent (which has full tool access).

    CRITICAL: We ALWAYS use v1 for execution because it has access to:
    - calculator tool (mandatory for math)
    - execute_python (for complex computations)
    - web_search (for factual lookups)

    The v1 agent achieves 95% accuracy BECAUSE of these tools.
    Never use direct LLM calls for math problems.
    """

    def __init__(self):
        # We don't need an LLM here - we delegate to v1
        pass

    def execute(self, subtask: SubTask, context: dict[int, str] = None) -> tuple[str, float]:
        """
        Execute a sub-task using the v1 agent (with full tool access).

        Args:
            subtask: The sub-task to execute
            context: Results from dependent sub-tasks

        Returns:
            Tuple of (result, confidence)
        """
        return self.execute_with_v1(subtask, context)

    def execute_with_v1(self, subtask: SubTask, context: dict[int, str] = None) -> tuple[str, float]:
        """
        Execute a sub-task using the v1 agent (via direct import).
        This provides robust reasoning with tool access.
        """
        from src.agent.graph import run_agent, get_final_answer

        # Build enhanced query with context from dependencies
        query = subtask.description
        if context and subtask.dependencies:
            context_parts = []
            for dep_id in subtask.dependencies:
                if dep_id in context:
                    context_parts.append(f"Given: The result from step {dep_id} is {context[dep_id]}")
            if context_parts:
                query = "\n".join(context_parts) + "\n\nNow solve: " + query

        try:
            result = run_agent(query)
            answer = get_final_answer(result)

            # ROBUST ANSWER EXTRACTION - try multiple patterns
            extracted = None
            
            # 1. GSM8K #### format (highest priority)
            hash_match = re.search(r'####\s*(-?\d+(?:,\d{3})*(?:\.\d+)?)', answer)
            if hash_match:
                extracted = hash_match.group(1).replace(',', '')
            
            # 2. **Final Answer: X** or Final Answer: X format
            if not extracted:
                final_match = re.search(r'\*?\*?[Ff]inal [Aa]nswer[:\s]*\*?\*?\s*(-?\d+(?:,\d{3})*(?:\.\d+)?)', answer)
                if final_match:
                    extracted = final_match.group(1).replace(',', '')
            
            # 3. "answer is X", "equals X", "= X" patterns
            if not extracted:
                ans_match = re.search(r'(?:answer\s+is|equals?|=)\s*\$?(-?\d+(?:,\d{3})*(?:\.\d+)?)', answer, re.IGNORECASE)
                if ans_match:
                    extracted = ans_match.group(1).replace(',', '')
            
            # 4. "X dollars/apples/etc" at end of sentence
            if not extracted:
                end_match = re.search(r'(-?\d+(?:,\d{3})*(?:\.\d+)?)\s*(?:dollars?|apples?|eggs?|cups?|meters?|sheep|chickens?|hours?|minutes?|bolts?|glasses?)?\s*[.!]?\s*$', answer, re.IGNORECASE)
                if end_match:
                    extracted = end_match.group(1).replace(',', '')
            
            # 5. Last resort: find the last number in the text
            if not extracted:
                all_nums = re.findall(r'(-?\d+(?:,\d{3})*(?:\.\d+)?)', answer)
                if all_nums:
                    extracted = all_nums[-1].replace(',', '')
            
            # Use extracted answer if found
            if extracted:
                answer = extracted

            # Count tool calls for confidence
            tool_calls = sum(
                1 for m in result.get("messages", [])
                if hasattr(m, "tool_calls") and m.tool_calls
            )
            confidence = min(0.7 + tool_calls * 0.1, 0.95)

            return answer, confidence

        except Exception as e:
            # If v1 fails, return error message (don't fallback to LLM-only)
            return f"Error: {str(e)}", 0.3


# ============================================================================
# VERIFICATION AGENT
# ============================================================================

VERIFICATION_PROMPT = """You are a Math Verification Agent. Your job is to verify if the proposed answer is correct.

VERIFICATION RULES:
1. **Trust the computation tools**: If the answer was computed using calculator/Python tools, it's likely correct.
2. **Check the logic, not the arithmetic**: Focus on whether the APPROACH matches the problem.
3. **Presumption of Correctness**: Only flag errors if you find a CLEAR logical mistake.
4. **Don't over-correct**: If the answer is reasonable and matches the problem's requirements, mark it valid.

Original Problem: {problem}
Proposed Answer: {answer}
Reasoning Summary: {reasoning}

Respond in this exact JSON format:
{{
    "is_valid": true | false,
    "confidence": 0.0 to 1.0,
    "issues": "Description of errors ONLY if is_valid is false, otherwise empty string",
    "corrected_answer": "Only if is_valid is false and you're CERTAIN of correction, otherwise null"
}}

Respond with ONLY JSON."""


class VerificationAgent:
    """Verifies answers for complex problems."""

    def __init__(self):
        self.llm = get_llm(temperature=0.0)

    def verify(self, problem: str, answer: str, reasoning: str = "") -> VerificationResult:
        """
        Verify an answer.

        Args:
            problem: Original problem
            answer: Proposed answer
            reasoning: Reasoning path taken

        Returns:
            VerificationResult
        """
        messages = [
            SystemMessage(content="You are a verification assistant that outputs only valid JSON."),
            HumanMessage(content=VERIFICATION_PROMPT.format(
                problem=problem,
                answer=answer,
                reasoning=reasoning[:1000] if reasoning else "Computed using calculator/Python tools"
            ))
        ]

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()

            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                data = json.loads(json_match.group())
            else:
                data = json.loads(content)

            issues = data.get("issues", "")
            if isinstance(issues, list):
                issues = issues
            elif issues:
                issues = [issues]
            else:
                issues = []

            return VerificationResult(
                is_valid=data.get("is_valid", True),
                confidence=data.get("confidence", 0.85),
                issues=issues,
                corrected_answer=data.get("corrected_answer") if data.get("corrected_answer") != "null" else None
            )

        except (json.JSONDecodeError, KeyError, Exception):
            # Assume valid if parsing fails - don't penalize good answers
            return VerificationResult(is_valid=True, confidence=0.8)


# ============================================================================
# SYNTHESIS AGENT
# ============================================================================

SYNTHESIS_PROMPT = """You are a Final Answer Synthesizer. Your job is to extract and format the final answer.

Original Problem: {problem}

Execution Results:
{results}

Verification Status: {verification}

SYNTHESIS RULES:
1. **Use the computed result**: The execution used calculator/Python tools, so trust the numerical result.
2. **Extract the number**: Your output should be just the final numerical answer.
3. **Format correctly**: End with exactly: #### [number]
4. **If verification corrected**: Use the corrected answer if verification found an error.

Provide ONLY the final answer in format: #### [number]"""


class SynthesisAgent:
    """Combines results into a final answer."""

    def __init__(self):
        self.llm = get_llm(temperature=0.0)

    def synthesize(
        self,
        problem: str,
        results: dict[int, str],
        subtasks: list[SubTask],
        verification: VerificationResult | None = None
    ) -> tuple[str, float]:
        """
        Synthesize final answer from sub-task results.

        Returns:
            Tuple of (final answer, confidence)
        """
        # If we have a single result and verification passed, just return it
        if len(results) == 1:
            answer = list(results.values())[0]
            # Clean up the answer - extract just the number
            hash_match = re.search(r'####\s*(-?\d+(?:\.\d+)?)', answer)
            if hash_match:
                answer = hash_match.group(1)
            else:
                num_match = re.search(r'(-?\d+(?:\.\d+)?)', answer)
                if num_match:
                    answer = num_match.group(1)

            confidence = 0.9
            if verification:
                if verification.is_valid:
                    confidence = max(confidence, verification.confidence)
                elif verification.corrected_answer:
                    # Use corrected answer
                    corr_match = re.search(r'(-?\d+(?:\.\d+)?)', verification.corrected_answer)
                    if corr_match:
                        answer = corr_match.group(1)
                    confidence = verification.confidence

            return answer, confidence

        # For multiple results, need to combine them
        results_str = "\n".join([
            f"Step {st.id} ({st.description[:50]}...): {results.get(st.id, 'N/A')}"
            for st in subtasks
        ])

        if verification:
            verif_str = f"Valid: {verification.is_valid}, Confidence: {verification.confidence:.0%}"
            if not verification.is_valid and verification.corrected_answer:
                verif_str += f", Corrected Answer: {verification.corrected_answer}"
        else:
            verif_str = "Passed"

        messages = [
            SystemMessage(content="You are a synthesis assistant. Output ONLY the final numeric answer."),
            HumanMessage(content=SYNTHESIS_PROMPT.format(
                problem=problem,
                results=results_str,
                verification=verif_str
            ))
        ]

        try:
            response = self.llm.invoke(messages)
            content = response.content.strip()

            # Extract final answer - prioritize #### format
            answer = content
            hash_match = re.search(r'####\s*(-?\d+(?:\.\d+)?)', content)
            if hash_match:
                answer = hash_match.group(1)
            else:
                # Find any number in the response
                all_nums = re.findall(r'(-?\d+(?:\.\d+)?)', content)
                if all_nums:
                    answer = all_nums[-1]

            confidence = 0.85
            if verification and verification.is_valid:
                confidence = 0.9

            return answer, confidence

        except Exception:
            # Fallback - return the last result
            if results:
                last_result = list(results.values())[-1]
                num_match = re.search(r'(-?\d+(?:\.\d+)?)', last_result)
                if num_match:
                    return num_match.group(1), 0.7
            return "Error", 0.0


# ============================================================================
# CONVENIENCE FUNCTIONS
# ============================================================================

def create_agents() -> tuple[PlanningAgent, ExecutionAgent, VerificationAgent, SynthesisAgent]:
    """Create all orchestrator agents."""
    return (
        PlanningAgent(),
        ExecutionAgent(),
        VerificationAgent(),
        SynthesisAgent()
    )
